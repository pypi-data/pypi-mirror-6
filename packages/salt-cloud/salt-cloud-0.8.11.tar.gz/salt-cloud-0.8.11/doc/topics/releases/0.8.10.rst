===============================
Salt Cloud 0.8.10 Release Notes
===============================

Welcome to 0.8.10! This is the last official release of Salt Cloud as its own
independent package. The entire repository has been merged upstream into the
main Salt repository. All future changes will be found there, and any future
issues and pull requests need to be filed there:

https://github.com/saltstack/salt

Existing issues in the Salt Cloud issue tracker will remain there, and efforts
to close standing issues there will continue. We will not, however, be able to
merge additional pull requests made against the old salt-cloud repository.

This release exists to provide to the community all of the changes made between
0.8.9 and the merger of Salt and Salt Cloud. This is due to significant demand
for a final Salt Cloud release to tide users over with the new features, and bug
fixes, until the next feature release of Salt.


Documentation
=============
The documentation for Salt Cloud can be found on Read the Docs:
http://salt-cloud.readthedocs.org


Download
========
Salt Cloud can be downloaded and install via pypi:

http://pypi.python.org/packages/source/s/salt-cloud/salt-cloud-0.8.10.tar.gz

Some packages have been made available for salt-cloud and more on on their
way. Packages for Arch and FreeBSD are being made available thanks to the
work of Christer Edwards, and packages for RHEL and Fedora are being created
by Clint Savage. The Ubuntu PPA is being managed by Sean Channel. Package
availability will be announced on the salt mailing list.


New Event System Code
=====================
The most important aspect of this release involves updating the event code in
Salt Cloud to handle the changes made to the event system in Salt 0.17.0.
Without these changes, machines will be spun up properly, and then appear to
fail. This release fixes that.


New SoftLayer Drivers
=====================
Drivers are available for both the SoftLayer Cloud Layer (`softlayer`) and the
SoftLayer Baremetal/Hardware Layer (`softlayer-hw`). These are especially
important, following IBM's announcement concerning phasing out their Smart Cloud
Enterprise product in January 2014 in favor of SoftLayer.

The configuration for both drivers is essentially identical:

``/etc/salt/cloud.providers`` or ``/etc/salt/cloud.providers.d/softlayer.conf``:

.. code-block:: yaml

    my-softlayer-config:
      # SoftLayer account api key
      user: MYLOGIN
      apikey: JVkbSJDGHSDKUKSDJfhsdklfjgsjdkflhjlsdfffhgdgjkenrtuinv
      provider: softlayer

    my-softlayer-hw-config:
      # SoftLayer account api key
      user: MYLOGIN
      apikey: JVkbSJDGHSDKUKSDJfhsdklfjgsjdkflhjlsdfffhgdgjkenrtuinv
      provider: softlayer-hw

However, profile configuration between the two is very different:

.. code-block:: yaml

    base_softlayer_ubuntu:
      provider: my-softlayer
      image: UBUNTU_LATEST
      cpu_number: 1
      ram: 1024
      disk_size: 100
      local_disk: True
      hourly_billing: True
      domain: example.com
      location: sjc01
      # Optional
      max_net_speed: 1000
      private_vlan: 396
      private_network: True
      private_ssh: True
      # May be used _instead_of_ image
      global_identifier: 320d8be5-46c0-dead-cafe-13e3c51

    base_softlayer_hw_centos:
      provider: my-softlayer-hw
      # CentOS 6.0 - Minimal Install (64 bit)
      image: 13963
      # 2 x 2.0 GHz Core Bare Metal Instance - 2 GB Ram
      size: 1921
      # 250GB SATA II
      hdd: 19
      # San Jose 01
      location: 168642
      domain: example.com
      # Optional
      vlan: 396
      port_speed: 273
      banwidth: 248

Those of you who are familiar with SoftLayer may already be comfortable with
these usages. For a more detailed discussion, check the SoftLayer Getting
Started guide:

http://salt-cloud.readthedocs.org/en/latest/topics/softlayer.html


Support for IOPS Volumes in EC2
===============================
It is now possible to specify a type when creating a new volume on EC2. The
default is `standard`, but it is now possible to specify `io1` instead. For
example:

.. code-block:: yaml

    base_ec2_db:
      provider: my-ec2-southeast-public-ips
      image: ami-e565ba8c
      size: m1.xlarge
      ssh_username: ec2-user
      volumes:
        - { size: 10, device: /dev/sdf }
        - { size: 10, device: /dev/sdg, type: io1, iops: 1000 }
        - { size: 10, device: /dev/sdh, type: io1, iops: 1000 }


Windows (Minion) Support
========================
Salt Cloud is now able to spin up minions on Windows servers. There are some
caveats here, mainly in that port 445 needs to be available on the Windows
image used (and this is usually not the default). For more information, check
the docs for Spinning up Windows Minions:

http://salt-cloud.readthedocs.org/en/latest/topics/windows.html


OpenStack Support for Userdata
==============================
The OpenStack driver now supports passing in a file to be sent into an instance
as `userdata`. Configuration in Salt Cloud itself is simple, and can be
performed in either the provider or profile configuration:

.. code-block:: yaml

    userdata_file: /tmp/userdata.txt

A more detailed explanation of that this setting does in OpenStack can be found
in their documentation:

http://docs.openstack.org/user-guide/content/user-data.html

